__author__ = "Jessika Nordin, Padraic Corcoran"
__copyright__ = "Copyright 2022"
__email__ = "jessika.nordin@scilifelab.uu.se"
__license__ = "GPL-3"


include: "rules/common.smk"
include: "rules/add_ref_to_vcf.smk"
include: "rules/coverage.smk"
include: "rules/peddy.smk"


report: "report/workflow.rst"


rule all:
    input:
        unpack(compile_output_list),


ruleorder: cnv_sv_manta_run_workflow_n > misc_bgzip
ruleorder: parabricks_fq2bam > alignment_samtools_index
ruleorder: qc_mosdepth > misc_bgzip
ruleorder: qc_mosdepth_bed > misc_bgzip


module alignment:
    snakefile:
        github("hydra-genetics/alignment", path="workflow/Snakefile", tag=config["modules"]["alignment"],)
    config:
        config


use rule samtools_sort from alignment as alignment_samtools_sort with:
    input:
        "cnv_sv/expansionhunter/{sample}_{type}_realigned.bam"
    output:
        temp("cnv_sv/expansionhunter/{sample}_{type}_realigned.sorted.bam")
    log:
        "cnv_sv/expansionhunter/{sample}_{type}_realigned.sorted.bam.log"
    benchmark:
        repeat(
            "cnv_sv/expansionhunter/{sample}_{type}_realigned.sorted.bam.benchmark.tsv",
            config.get("samtools_sort", {}).get("benchmark_repeats", 1),
        )


use rule samtools_index from alignment as alignment_samtools_index 


module annotation:
    snakefile:
        github(
            "hydra-genetics/annotation",
            path="workflow/Snakefile",
            tag=config["modules"]["annotation"],
        )
    config:
        config


use rule stranger from annotation as annotation_stranger


module cnv_sv:
    snakefile:
        github(
            "hydra-genetics/cnv_sv",
            path="workflow/Snakefile",
            tag=config["modules"]["cnv_sv"],
        )
    config:
        config


use rule cnvpytor_filter from cnv_sv as cnv_sv_cnvpytor_filter


use rule cnvpytor_readdepth from cnv_sv as cnv_sv_cnvpytor_rd with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        vcf="parabricks/pbrun_deepvariant/{sample}.vcf",


use rule expansionhunter from cnv_sv as cnv_sv_expansionhunter with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_{type}.bam.bai",
        cat=config.get("expansionhunter", {}).get("variant_catalog", ""),
        ref=config.get("reference", {}).get("fasta", ""),
        sex="qc/peddy/peddy.sex_check.csv",


use rule manta_config_n from cnv_sv as cnv_sv_manta_config_n with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_N.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_N.bam.bai",
        ref=config["reference"]["fasta"],


use rule manta_run_workflow_n from cnv_sv as cnv_sv_manta_run_workflow_n with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_N.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_N.bam.bai",
        ref=config["reference"]["fasta"],
        scrpt="cnv_sv/manta_run_workflow_n/{sample}/runWorkflow.py",
    output:
        cand_si_vcf=temp("cnv_sv/manta_run_workflow_n/{sample}/results/variants/candidateSmallIndels.vcf.gz"),
        cand_si_tbi=temp("cnv_sv/manta_run_workflow_n/{sample}/results/variants/candidateSmallIndels.vcf.gz.tbi"),
        cand_sv_vcf=temp("cnv_sv/manta_run_workflow_n/{sample}/results/variants/candidateSV.vcf.gz"),
        cand_sv_tbi=temp("cnv_sv/manta_run_workflow_n/{sample}/results/variants/candidateSV.vcf.gz.tbi"),
        dip_sv_vcf=temp("cnv_sv/manta_run_workflow_n/{sample}/results/variants/diploidSV.vcf.gz"),
        dip_sv_tbi=temp("cnv_sv/manta_run_workflow_n/{sample}/results/variants/diploidSV.vcf.gz.tbi"),
        wrk_dir=temp(directory("cnv_sv/manta_run_workflow_n/{sample}/workspace")),


use rule reviewer_genrate_locus_list from cnv_sv as cnv_sv_generate_reviewer


use rule reviewer from cnv_sv as cnv_sv_reviewer


use rule svdb_merge from cnv_sv as cnv_sv_svdb_merge with:
    input:
        vcfs=[
            "cnv_sv/tiddit/{sample}_{type}.vcf",
            "cnv_sv/manta_run_workflow_n/{sample}/results/variants/diploidSV.vcf.gz",
            "cnv_sv/cnvpytor/{sample}_{type}.vcf",
        ],


use rule svdb_query from cnv_sv as cnv_sv_svdb_query with:
    output:
        vcf=temp("cnv_sv/svdb_query/{sample}_{type}.svdb_query.vcf"),


use rule tiddit from cnv_sv as cnv_sv_tiddit with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        ref=config["reference"]["fasta"],


module compression:
    snakefile:
        github(
            "hydra-genetics/compression",
            path="workflow/Snakefile",
            tag=config["modules"]["compression"],
        )
    config:
        config


use rule * from compression as compression_*


use rule crumble from compression as compression_crumble


use rule samtools_view from compression as compression_samtools_view with:
    input:
        bam="parabricks/pbrun_fq2bam/{file}.bam",
        bai="parabricks/pbrun_fq2bam/{file}.bam.bai",
        ref=config.get("reference", {}).get("fasta", ""),


use rule spring from compression as compression_spring with:
    output:
        spring=temp("compression/spring/{sample}_{flowcell}_{lane}_{barcode}_{type}.spring"),


module filtering:
    snakefile:
        github("hydra-genetics/filtering", path="workflow/Snakefile", tag="b7f4dc3")
    config:
        config


use rule * from filtering as filtering_*


module misc:
    snakefile:
        github("hydra-genetics/misc", path="workflow/Snakefile", tag=config["modules"]["misc"])
    config:
        config


use rule samtools_index from misc as misc_samtools_index with:
    input:
        cram="{file}.crumble.cram",
    output:
        crai=temp("{file}.crumble.cram.crai"),
    params:
        extra=config.get("extra", {}).get("extra", ""),
    log:
        "{file}.crumble.cram.crai.log",
    benchmark:
        repeat(
            "{file}.crumble.cram.crai.benchmark.tsv",
            config.get("samtools_index", {}).get("benchmark_repeats", 1),
        )
    message:
        "{rule}: Index {wildcards.file}.crumble.cram file"


use rule bgzip from misc as misc_bgzip


use rule tabix from misc as misc_tabix


module mitochondrial:
    snakefile:
        github(
            "hydra-genetics/mitochondrial",
            path="workflow/Snakefile",
            tag=config["modules"]["mitochondrial"],
        )
    config:
        config


use rule * from mitochondrial as mitochondrial_*

use rule gatk_print_reads from mitochondrial as mitochondrial_gatk_print_reads with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_{type}.bam.bai",


module parabricks:
    snakefile:
        github(
            "hydra-genetics/parabricks",
            path="workflow/Snakefile",
            tag=config["modules"]["parabricks"],
        )
    config:
        config


use rule pbrun_fq2bam from parabricks as parabricks_fq2bam with:
    params:
        extra=config.get("parabricks_fq2bam", {}).get("extra", ""),
        in_fq=get_in_fq,
        num_gpus=config.get("parabricks_fq2bam", {}).get("num_gpus", ""),


use rule pbrun_deepvariant from parabricks as parabricks_deepvariant with:
    params:
        extra=config.get("parabricks_deepvariant", {}).get("extra", ""),
        num_gpus=config.get("parabricks_fq2bam", {}).get("num_gpus", ""),


module prealignment:
    snakefile:
        github(
            "hydra-genetics/prealignment",
            path="workflow/Snakefile",
            tag=config["modules"]["prealignment"],
        )
    config:
        config


use rule * from prealignment as prealignment_*


module qc:
    snakefile:
        github(
            "hydra-genetics/qc",
            path="workflow/Snakefile",
            tag=config["modules"]["qc"],
        )
    config:
        config


use rule fastqc from qc as qc_fastqc


use rule mosdepth from qc as qc_mosdepth with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_{type}.bam.bai",


use rule mosdepth_bed from qc as qc_mosdepth_bed with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_{type}.bam.bai",
        bed=config.get("reference", {}).get("coverage_bed", ""),
    output:
        bed=temp("qc/mosdepth_bed/{sample}_{type}.regions.bed.gz"),
        bed_csi=temp("qc/mosdepth_bed/{sample}_{type}.regions.bed.gz.csi"),
        glob=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.global.dist.txt"),
        pairbase=temp("qc/mosdepth_bed/{sample}_{type}.per-base.bed.gz"),
        region=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.region.dist.txt"),
        summary=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.summary.txt"),
        thresholds=temp("qc/mosdepth_bed/{sample}_{type}.thresholds.bed.gz"),
    params:
        thresholds="10,20,30",


use rule multiqc from qc as qc_multiqc


use rule peddy from qc as qc_peddy


use rule picard_collect_alignment_summary_metrics from qc as qc_pic_align_sum_met with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        ref=config["reference"]["fasta"],


use rule picard_collect_duplication_metrics from qc as qc_pic_dup_met with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",


use rule picard_collect_gc_bias_metrics from qc as qc_pic_gc_met with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        ref=config["reference"]["fasta"],


use rule picard_collect_hs_metrics from qc as qc_pic_hs_met with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bait_intervals=config["reference"]["exome_intervals"],
        target_intervals=config["reference"]["exome_intervals"],
        reference=config["reference"]["fasta"],


use rule picard_collect_insert_size_metrics from qc as qc_pic_ins_size with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",


use rule picard_collect_multiple_metrics from qc as qc_pic_multi_met with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        ref=config["reference"]["fasta"],


use rule picard_collect_wgs_metrics from qc as qc_pic_wgs_met with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        ref=config["reference"]["fasta"],
        interval=config["reference"]["wgs_intervals"],


use rule samtools_stats from qc as qc_samtools_stats with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",


use rule samtools_idxstats from qc as qc_samtools_idxstats with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_{type}.bam.bai",
    output:
        temp("qc/samtools_idxstats/{sample}_{type}.samtools-idxstats.txt"),


module snv_indels:
    snakefile:
        github(
            "hydra-genetics/snv_indels",
            path="workflow/Snakefile",
            tag=config["modules"]["snv_indels"],
        )
    config:
        config


use rule deepvariant from snv_indels as snv_indels_deepvariant with:
    input:
        bam="parabricks/pbrun_fq2bam/{sample}_{type}.bam",
        bai="parabricks/pbrun_fq2bam/{sample}_{type}.bam.bai",
        ref=config.get("reference", {}).get("fasta", ""),
    output:
        gvcf=temp("snv_indels/deepvariant/{sample}_{type}.g.vcf"),
        vcf=temp("snv_indels/deepvariant/{sample}_{type}.vcf"),
